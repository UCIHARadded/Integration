# ğŸ”¬ Integration Framework for Domain Generalization with GNNs, SHAP, and Curriculum Learning

## ğŸ§  Overview

This repository provides an integrated framework for research in Domain Generalization (DG) using Graph Neural Networks (GNNs), SHAP-based interpretability, and Curriculum Learning strategies. It extends the DIVERSIFY architecture with automation of latent domain estimation, curriculum learning and SHAP evaluation tools. The framework supports continual learning setups, clustering-based domain estimation, and perturbation-based interpretability evaluation.

---

## ğŸš€ Core Pipelines

### ğŸ”§ Training Pipeline

Argument Parsing â€“ Loads dataset, model, algorithm, and SHAP configurations via get_args().

Dataset Preparation â€“ Uses get_act_dataloader for EMG data loading with train-test splits.

Network Construction â€“ Initializes networks via ActNetwork or adversarial models.

Curriculum Learning â€“ Optionally reorders samples based on clustering difficulty (get_curriculum_loader).

Optimization â€“ Uses optimizers and loss functions defined in alg/opt.py and loss/common_loss.py.

Training Loop â€“ Iterates through epochs, records metrics, evaluates on validation sets.

SHAP Analysis â€“ Computes SHAP values to explain model decisions and integrates interpretability in training.

Artifacts Saving â€“ Saves models, SHAP explanations, and plots for analysis.

        train.py --> datautil/ --> alg/ --> loss/ --> network/
        

Training Pipeline Illustration:

      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Raw Data  â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Domain Split â”‚<â”€â”€â”€â–¶â”‚ Cluster Estimation â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼                         â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Curriculum   â”‚â”€â”€â”€â”€â–¶ â”‚ Model Training   â”‚
      â”‚ Learning     â”‚      â”‚      (CNN)       â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ Save Trained     â”‚
                            â”‚ Weights & Logs   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            

### ğŸ“Š Evaluation Pipeline

Model Loading â€“ Loads trained models from checkpoint directories.

Test Dataset Preparation â€“ Uses held-out test splits.

Performance Evaluation â€“ Computes metrics including accuracy, confusion matrices, silhouette score, Davies-Bouldin index.

SHAP-based Analysis â€“ Generates heatmaps, flip-rate, Jaccard similarity, and Kendall Tau correlations for interpretability.

Results Saving â€“ Outputs are saved as images (.png), numpy arrays, and printed summaries.


Evaluation Pipeline Illustration:

      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Test Data  â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Load Trained Model â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Inference & SHAP Analysis  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Explanation Metricsâ”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## âœ¨ Key Features

            âœ… Supports Diversify Algorithm for sample-level generalisation.
                
            âœ… Automated Latent Domain Estimation using clustering.
        
            âœ… Curriculum Learning for sequential and staged domain training.
        
            âœ… SHAP Explainability to visualise feature importance in time series.
        
            âœ… Cross-domain Testing with configurable datasets.
        
            âœ… Extensible Pipeline for novel DG/DA experiments.

            âœ… Evaluation metrics include Silhouette, Davies-Bouldin, Confusion Matrices.

            âœ… Clean separation of data utilities, losses, algorithms, and network architectures.

---
            
## ğŸ“ File Structure

                Integration-main/
                â”œâ”€â”€ alg/                        # Core domain generalization algorithms
                â”‚   â”œâ”€â”€ algs/                   # Specific algorithm implementations (e.g. diversify.py)
                â”‚   â”œâ”€â”€ alg.py                  # Main algorithm controller
                â”‚   â””â”€â”€ modelopera.py           # Model operations
                â”œâ”€â”€ datautil/                   # Data loaders, curriculum sorting, clustering
                â”‚   â”œâ”€â”€ actdata/                # Activity recognition dataset utilities
                â”‚   â”œâ”€â”€ getcurriculumloader.py
                â”‚   â”œâ”€â”€ getdataloader_single.py
                â”‚   â””â”€â”€ cluster.py              # Clustering logic for domain estimation
                â”œâ”€â”€ loss/                       # Custom loss functions
                â”‚   â””â”€â”€ common_loss.py
                â”œâ”€â”€ network/                    # Model architectures
                â”‚   â”œâ”€â”€ act_network.py          # CNN for activity data
                â”‚   â”œâ”€â”€ Adver_network.py        # Adversarial components
                â”‚   â””â”€â”€ common_network.py       # Base models
                â”œâ”€â”€ utils/                      # Utility functions and argument parsing
                â”‚   â”œâ”€â”€ params.py
                â”‚   â””â”€â”€ util.py
                â”œâ”€â”€ shap_utils.py               # SHAP evaluation metrics
                â”œâ”€â”€ train.py                    # Entry point for training
                â”œâ”€â”€ env.yml                     # Conda environment spec
                â””â”€â”€ README.md                   # This file

---

## ğŸ“Š Supported Datasets

Currently supports activity recognition datasets, especially cross-subject and cross-location setups via:

    actdata/cross_people.py

EMG dataset (with preprocessing expected in CSV format)

Extendable to any time series dataset following the Dataset class templates.

Direct Link- https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip

---

## â–¶ï¸ How to Run

### ğŸ“¦ Setup

        conda env create -f env.yml
        conda activate diversify_env

### Dataset download 

        # Download the dataset
        !wget https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip
        !unzip diversity_emg.zip && mv emg data/
        
        # Create necessary directories
        !mkdir -p ./data/train_output/act/
        
        !mkdir -p ./data/emg
        !mv emg/* ./data/emg

### ğŸ‹ï¸â€â™‚ï¸ Training


        python train.py --data_dir ./data/ --task cross_people --test_envs 0 --dataset emg --algorithm diversify --alpha1 1.0 --alpha 1.0 --lam 0.0 --local_epoch 3 --max_epoch 50 --lr 0.01 --output ./train_output --automated_k --curriculum --CL_PHASE_EPOCHS 20 --enable_shap
        
        python train.py --data_dir ./data/ --task cross_people --test_envs 1 --dataset emg --algorithm diversify --alpha1 0.1 --alpha 10.0 --lam 0.0 --local_epoch 2 --max_epoch 15 --lr 0.01 --output ./data/train_output1 --automated_k --curriculum --CL_PHASE_EPOCHS 10 --enable_shap
        
        python train.py --data_dir ./data/ --task cross_people --test_envs 2 --dataset emg --algorithm diversify --alpha1 0.5 --alpha 21.5 --lam 0.0 --local_epoch 1 --max_epoch 150 --lr 0.01 --output ./data/train_output2 --automated_k --curriculum --CL_PHASE_EPOCHS 2 --enable_shap
        
        python train.py --data_dir ./data/ --task cross_people --test_envs 3 --dataset emg --algorithm diversify --alpha1 5.0 --alpha 0.1 --lam 0.0 --local_epoch 5 --max_epoch 30 --lr 0.01 --output ./data/train_output3 --automated_k --curriculum --CL_PHASE_EPOCHS 5 --enable_shap



### ğŸ§ª Evaluation

After training, use the same script with --eval flag (if implemented) or embed evaluation in train.py by enabling SHAP.

---

## ğŸ“‚ Outputs and Artifacts

        ./checkpoints/: Trained model weights.
        
        ./logs/: Training loss and accuracy logs.
        
        ./results/: SHAP metrics, AOPC plots, domain generalization reports, Confusion Matrices, Domain Cluster output for curriculum learning, Logs and Metrics stored in output folders defined within the script.
    

Typical evaluation output includes:

        Metric	                   Description
        Flip Rate	Change in prediction after key feature masking
        AOPC	   Confidence drop curve area
        Coherence	Agreement across similar inputs
        Sparsity	Minimum features required to explain

---
        
                
## ğŸ” In-depth Analysis

    Latent Domain Clustering: Uses KMeans-based latent splitting via datautil/cluster.py.

    Curriculum Training: Orders samples by feature norm or confidence before training.

    SHAP Explanations: shap_utils.py implements post-hoc perturbation evaluations and ranking metrics.

    Cross-Domain Testing: Evaluates generalization across unseen person IDs or locations.

---

## ğŸ“œ License

This project is free for academic and commercial use with attribution.

            @misc{Integration2025,
              title={Integration Framework for Domain Generalization with GNNs, SHAP, and Curriculum Learning},
              author={Rishabh Gupta et al.},
              year={2025},
              note={https://github.com/UCIHARadded/Integration}
            }

---

## Contact

E-mail- rishabhgupta8218@gmail.com
