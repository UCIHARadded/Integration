{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m55G7AogCfET",
        "outputId": "a0ce8dbc-2fe9-48b0-eae2-f7354fe1cf2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Integration'...\n",
            "remote: Enumerating objects: 580, done.\u001b[K\n",
            "remote: Counting objects: 100% (229/229), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 580 (delta 192), reused 141 (delta 141), pack-reused 351 (from 1)\u001b[K\n",
            "Receiving objects: 100% (580/580), 230.47 KiB | 1.23 MiB/s, done.\n",
            "Resolving deltas: 100% (341/341), done.\n",
            "/content/Integration\n",
            "/content/Integration\n"
          ]
        }
      ],
      "source": [
        "# First clone the repository\n",
        "!git clone https://github.com/UCIHARadded/Integration.git\n",
        "%cd Integration\n",
        "\n",
        "# Verify current directory\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!wget https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip\n",
        "!unzip diversity_emg.zip && mv emg data/\n",
        "\n",
        "# Create necessary directories\n",
        "!mkdir -p ./data/train_output/act/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16xB-m55Cwe4",
        "outputId": "bb258d3e-d24a-4321-b661-8a3851e3501e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-01 18:13:46--  https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip\n",
            "Resolving wjdcloud.blob.core.windows.net (wjdcloud.blob.core.windows.net)... 20.60.131.4\n",
            "Connecting to wjdcloud.blob.core.windows.net (wjdcloud.blob.core.windows.net)|20.60.131.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20237244 (19M) [application/zip]\n",
            "Saving to: ‘diversity_emg.zip’\n",
            "\n",
            "diversity_emg.zip   100%[===================>]  19.30M  1.81MB/s    in 15s     \n",
            "\n",
            "2025-07-01 18:14:02 (1.30 MB/s) - ‘diversity_emg.zip’ saved [20237244/20237244]\n",
            "\n",
            "Archive:  diversity_emg.zip\n",
            "   creating: emg/\n",
            "   creating: emg/20/\n",
            "  inflating: emg/20/1_raw_data_11-41_22.03.16.txt  \n",
            "  inflating: emg/20/2_raw_data_11-43_22.03.16.txt  \n",
            "   creating: emg/35/\n",
            "  inflating: emg/35/2_raw_data_10-05_13.04.16.txt  \n",
            "  inflating: emg/35/1_raw_data_10-03_13.04.16.txt  \n",
            "   creating: emg/09/\n",
            "  inflating: emg/09/1_raw_data_12-41_23.03.16.txt  \n",
            "  inflating: emg/09/2_raw_data_12-43_23.03.16.txt  \n",
            "   creating: emg/15/\n",
            "  inflating: emg/15/2_raw_data_08-51_13.04.16.txt  \n",
            "  inflating: emg/15/1_raw_data_08-49_13.04.16.txt  \n",
            "   creating: emg/22/\n",
            "  inflating: emg/22/1_raw_data_12-37_28.03.16.txt  \n",
            "  inflating: emg/22/2_raw_data_12-39_28.03.16.txt  \n",
            "   creating: emg/13/\n",
            "  inflating: emg/13/1_raw_data_13-26_21.03.16.txt  \n",
            "  inflating: emg/13/2_raw_data_13-29_21.03.16.txt  \n",
            "   creating: emg/30/\n",
            "  inflating: emg/30/1_raw_data_09-49_21.03.16.txt  \n",
            "  inflating: emg/30/2_raw_data_09-50_21.03.16.txt  \n",
            "   creating: emg/01/\n",
            "  inflating: emg/01/2_raw_data_13-13_22.03.16.txt  \n",
            "  inflating: emg/01/1_raw_data_13-12_22.03.16.txt  \n",
            "   creating: emg/28/\n",
            "  inflating: emg/28/1_raw_data_12-10_15.04.16.txt  \n",
            "  inflating: emg/28/2_raw_data_12-11_15.04.16.txt  \n",
            "  inflating: emg/README.txt          \n",
            "   creating: emg/34/\n",
            "  inflating: emg/34/2_raw_data_10-53_07.04.16.txt  \n",
            "  inflating: emg/34/1_raw_data_10-51_07.04.16.txt  \n",
            "   creating: emg/06/\n",
            "  inflating: emg/06/2_raw_data_10-40_11.04.16.txt  \n",
            "  inflating: emg/06/1_raw_data_10-38_11.04.16.txt  \n",
            "   creating: emg/25/\n",
            "  inflating: emg/25/2_raw_data_14-53_24.04.16.txt  \n",
            "  inflating: emg/25/1_raw_data_14-51_24.04.16.txt  \n",
            "   creating: emg/26/\n",
            "  inflating: emg/26/2_raw_data_10-23_29.03.16.txt  \n",
            "  inflating: emg/26/1_raw_data_10-22_29.03.16.txt  \n",
            "   creating: emg/36/\n",
            "  inflating: emg/36/1_raw_data_13-03_15.04.16.txt  \n",
            "  inflating: emg/36/2_raw_data_13-04_15.04.16.txt  \n",
            "   creating: emg/04/\n",
            "  inflating: emg/04/1_raw_data_18-02_24.04.16.txt  \n",
            "  inflating: emg/04/2_raw_data_18-03_24.04.16.txt  \n",
            "   creating: emg/14/\n",
            "  inflating: emg/14/2_raw_data_09-51_15.04.16.txt  \n",
            "  inflating: emg/14/1_raw_data_09-50_15.04.16.txt  \n",
            "   creating: emg/02/\n",
            "  inflating: emg/02/2_raw_data_14-21_22.03.16.txt  \n",
            "  inflating: emg/02/1_raw_data_14-19_22.03.16.txt  \n",
            "   creating: emg/27/\n",
            "  inflating: emg/27/1_raw_data_12-19_06.04.16.txt  \n",
            "  inflating: emg/27/2_raw_data_12-20_06.04.16.txt  \n",
            "   creating: emg/17/\n",
            "  inflating: emg/17/2_raw_data_11-20_23.03.16.txt  \n",
            "  inflating: emg/17/1_raw_data_11-19_23.03.16.txt  \n",
            "  inflating: emg/emg_x.npy           \n",
            "   creating: emg/03/\n",
            "  inflating: emg/03/1_raw_data_09-32_11.04.16.txt  \n",
            "  inflating: emg/03/2_raw_data_09-34_11.04.16.txt  \n",
            "   creating: emg/31/\n",
            "  inflating: emg/31/2_raw_data_11-16_11.04.16.txt  \n",
            "  inflating: emg/31/1_raw_data_11-15_11.04.16.txt  \n",
            "   creating: emg/11/\n",
            "  inflating: emg/11/1_raw_data_13-11_18.03.16.txt  \n",
            "  inflating: emg/11/2_raw_data_13-13_18.03.16.txt  \n",
            "   creating: emg/21/\n",
            "  inflating: emg/21/2_raw_data_20-30_24.04.16.txt  \n",
            "  inflating: emg/21/1_raw_data_20-28_24.04.16.txt  \n",
            "   creating: emg/10/\n",
            "  inflating: emg/10/1_raw_data_11-08_21.03.16.txt  \n",
            "  inflating: emg/10/2_raw_data_11-10_21.03.16.txt  \n",
            "   creating: emg/05/\n",
            "  inflating: emg/05/2_raw_data_10-29_30.03.16.txt  \n",
            "  inflating: emg/05/1_raw_data_10-28_30.03.16.txt  \n",
            "   creating: emg/19/\n",
            "  inflating: emg/19/1_raw_data_12-10_26.04.16.txt  \n",
            "  inflating: emg/19/2_raw_data_12-11_26.04.16.txt  \n",
            "   creating: emg/08/\n",
            "  inflating: emg/08/1_raw_data_12-14_23.03.16.txt  \n",
            "  inflating: emg/08/2_raw_data_12-16_23.03.16.txt  \n",
            "   creating: emg/12/\n",
            "  inflating: emg/12/2_raw_data_11-36_28.03.16.txt  \n",
            "  inflating: emg/12/1_raw_data_11-35_28.03.16.txt  \n",
            "   creating: emg/16/\n",
            "  inflating: emg/16/2_raw_data_12-14_25.04.16.txt  \n",
            "  inflating: emg/16/1_raw_data_12-12_25.04.16.txt  \n",
            "   creating: emg/24/\n",
            "  inflating: emg/24/1_raw_data_10-16_12.04.16.txt  \n",
            "  inflating: emg/24/2_raw_data_10-17_12.04.16.txt  \n",
            "   creating: emg/33/\n",
            "  inflating: emg/33/2_raw_data_09-50_12.04.16.txt  \n",
            "  inflating: emg/33/1_raw_data_09-49_12.04.16.txt  \n",
            "   creating: emg/07/\n",
            "  inflating: emg/07/2_raw_data_18-50_22.03.16.txt  \n",
            "  inflating: emg/07/1_raw_data_18-48_22.03.16.txt  \n",
            "   creating: emg/32/\n",
            "  inflating: emg/32/2_raw_data_12-06_27.04.16.txt  \n",
            "  inflating: emg/32/1_raw_data_12-04_27.04.16.txt  \n",
            "   creating: emg/18/\n",
            "  inflating: emg/18/1_raw_data_12-35_21.03.16.txt  \n",
            "  inflating: emg/18/2_raw_data_12-37_21.03.16.txt  \n",
            "   creating: emg/23/\n",
            "  inflating: emg/23/1_raw_data_13-18_05.04.16.txt  \n",
            "  inflating: emg/23/2_raw_data_13-19_05.04.16.txt  \n",
            "   creating: emg/29/\n",
            "  inflating: emg/29/2_raw_data_10-18_15.04.16.txt  \n",
            "  inflating: emg/29/1_raw_data_10-17_15.04.16.txt  \n",
            "  inflating: emg/emg_y.npy           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip diversity_emg.zip\n",
        "!mkdir -p ./data/emg\n",
        "!mv emg/* ./data/emg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdWdOB8gCwXT",
        "outputId": "16b585c0-e33d-4a81-aaf0-aba7dab77e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  diversity_emg.zip\n",
            "   creating: emg/\n",
            "   creating: emg/20/\n",
            "  inflating: emg/20/1_raw_data_11-41_22.03.16.txt  \n",
            "  inflating: emg/20/2_raw_data_11-43_22.03.16.txt  \n",
            "   creating: emg/35/\n",
            "  inflating: emg/35/2_raw_data_10-05_13.04.16.txt  \n",
            "  inflating: emg/35/1_raw_data_10-03_13.04.16.txt  \n",
            "   creating: emg/09/\n",
            "  inflating: emg/09/1_raw_data_12-41_23.03.16.txt  \n",
            "  inflating: emg/09/2_raw_data_12-43_23.03.16.txt  \n",
            "   creating: emg/15/\n",
            "  inflating: emg/15/2_raw_data_08-51_13.04.16.txt  \n",
            "  inflating: emg/15/1_raw_data_08-49_13.04.16.txt  \n",
            "   creating: emg/22/\n",
            "  inflating: emg/22/1_raw_data_12-37_28.03.16.txt  \n",
            "  inflating: emg/22/2_raw_data_12-39_28.03.16.txt  \n",
            "   creating: emg/13/\n",
            "  inflating: emg/13/1_raw_data_13-26_21.03.16.txt  \n",
            "  inflating: emg/13/2_raw_data_13-29_21.03.16.txt  \n",
            "   creating: emg/30/\n",
            "  inflating: emg/30/1_raw_data_09-49_21.03.16.txt  \n",
            "  inflating: emg/30/2_raw_data_09-50_21.03.16.txt  \n",
            "   creating: emg/01/\n",
            "  inflating: emg/01/2_raw_data_13-13_22.03.16.txt  \n",
            "  inflating: emg/01/1_raw_data_13-12_22.03.16.txt  \n",
            "   creating: emg/28/\n",
            "  inflating: emg/28/1_raw_data_12-10_15.04.16.txt  \n",
            "  inflating: emg/28/2_raw_data_12-11_15.04.16.txt  \n",
            "  inflating: emg/README.txt          \n",
            "   creating: emg/34/\n",
            "  inflating: emg/34/2_raw_data_10-53_07.04.16.txt  \n",
            "  inflating: emg/34/1_raw_data_10-51_07.04.16.txt  \n",
            "   creating: emg/06/\n",
            "  inflating: emg/06/2_raw_data_10-40_11.04.16.txt  \n",
            "  inflating: emg/06/1_raw_data_10-38_11.04.16.txt  \n",
            "   creating: emg/25/\n",
            "  inflating: emg/25/2_raw_data_14-53_24.04.16.txt  \n",
            "  inflating: emg/25/1_raw_data_14-51_24.04.16.txt  \n",
            "   creating: emg/26/\n",
            "  inflating: emg/26/2_raw_data_10-23_29.03.16.txt  \n",
            "  inflating: emg/26/1_raw_data_10-22_29.03.16.txt  \n",
            "   creating: emg/36/\n",
            "  inflating: emg/36/1_raw_data_13-03_15.04.16.txt  \n",
            "  inflating: emg/36/2_raw_data_13-04_15.04.16.txt  \n",
            "   creating: emg/04/\n",
            "  inflating: emg/04/1_raw_data_18-02_24.04.16.txt  \n",
            "  inflating: emg/04/2_raw_data_18-03_24.04.16.txt  \n",
            "   creating: emg/14/\n",
            "  inflating: emg/14/2_raw_data_09-51_15.04.16.txt  \n",
            "  inflating: emg/14/1_raw_data_09-50_15.04.16.txt  \n",
            "   creating: emg/02/\n",
            "  inflating: emg/02/2_raw_data_14-21_22.03.16.txt  \n",
            "  inflating: emg/02/1_raw_data_14-19_22.03.16.txt  \n",
            "   creating: emg/27/\n",
            "  inflating: emg/27/1_raw_data_12-19_06.04.16.txt  \n",
            "  inflating: emg/27/2_raw_data_12-20_06.04.16.txt  \n",
            "   creating: emg/17/\n",
            "  inflating: emg/17/2_raw_data_11-20_23.03.16.txt  \n",
            "  inflating: emg/17/1_raw_data_11-19_23.03.16.txt  \n",
            "  inflating: emg/emg_x.npy           \n",
            "   creating: emg/03/\n",
            "  inflating: emg/03/1_raw_data_09-32_11.04.16.txt  \n",
            "  inflating: emg/03/2_raw_data_09-34_11.04.16.txt  \n",
            "   creating: emg/31/\n",
            "  inflating: emg/31/2_raw_data_11-16_11.04.16.txt  \n",
            "  inflating: emg/31/1_raw_data_11-15_11.04.16.txt  \n",
            "   creating: emg/11/\n",
            "  inflating: emg/11/1_raw_data_13-11_18.03.16.txt  \n",
            "  inflating: emg/11/2_raw_data_13-13_18.03.16.txt  \n",
            "   creating: emg/21/\n",
            "  inflating: emg/21/2_raw_data_20-30_24.04.16.txt  \n",
            "  inflating: emg/21/1_raw_data_20-28_24.04.16.txt  \n",
            "   creating: emg/10/\n",
            "  inflating: emg/10/1_raw_data_11-08_21.03.16.txt  \n",
            "  inflating: emg/10/2_raw_data_11-10_21.03.16.txt  \n",
            "   creating: emg/05/\n",
            "  inflating: emg/05/2_raw_data_10-29_30.03.16.txt  \n",
            "  inflating: emg/05/1_raw_data_10-28_30.03.16.txt  \n",
            "   creating: emg/19/\n",
            "  inflating: emg/19/1_raw_data_12-10_26.04.16.txt  \n",
            "  inflating: emg/19/2_raw_data_12-11_26.04.16.txt  \n",
            "   creating: emg/08/\n",
            "  inflating: emg/08/1_raw_data_12-14_23.03.16.txt  \n",
            "  inflating: emg/08/2_raw_data_12-16_23.03.16.txt  \n",
            "   creating: emg/12/\n",
            "  inflating: emg/12/2_raw_data_11-36_28.03.16.txt  \n",
            "  inflating: emg/12/1_raw_data_11-35_28.03.16.txt  \n",
            "   creating: emg/16/\n",
            "  inflating: emg/16/2_raw_data_12-14_25.04.16.txt  \n",
            "  inflating: emg/16/1_raw_data_12-12_25.04.16.txt  \n",
            "   creating: emg/24/\n",
            "  inflating: emg/24/1_raw_data_10-16_12.04.16.txt  \n",
            "  inflating: emg/24/2_raw_data_10-17_12.04.16.txt  \n",
            "   creating: emg/33/\n",
            "  inflating: emg/33/2_raw_data_09-50_12.04.16.txt  \n",
            "  inflating: emg/33/1_raw_data_09-49_12.04.16.txt  \n",
            "   creating: emg/07/\n",
            "  inflating: emg/07/2_raw_data_18-50_22.03.16.txt  \n",
            "  inflating: emg/07/1_raw_data_18-48_22.03.16.txt  \n",
            "   creating: emg/32/\n",
            "  inflating: emg/32/2_raw_data_12-06_27.04.16.txt  \n",
            "  inflating: emg/32/1_raw_data_12-04_27.04.16.txt  \n",
            "   creating: emg/18/\n",
            "  inflating: emg/18/1_raw_data_12-35_21.03.16.txt  \n",
            "  inflating: emg/18/2_raw_data_12-37_21.03.16.txt  \n",
            "   creating: emg/23/\n",
            "  inflating: emg/23/1_raw_data_13-18_05.04.16.txt  \n",
            "  inflating: emg/23/2_raw_data_13-19_05.04.16.txt  \n",
            "   creating: emg/29/\n",
            "  inflating: emg/29/2_raw_data_10-18_15.04.16.txt  \n",
            "  inflating: emg/29/1_raw_data_10-17_15.04.16.txt  \n",
            "  inflating: emg/emg_y.npy           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --data_dir ./data/ \\\n",
        "  --task cross_people \\\n",
        "  --test_envs 0 \\\n",
        "  --dataset emg \\\n",
        "  --algorithm diversify \\\n",
        "  --latent_domain_num 10 \\\n",
        "  --alpha1 1.0 \\\n",
        "  --alpha 1.0 \\\n",
        "  --lam 0.0 \\\n",
        "  --local_epoch 3 \\\n",
        "  --max_epoch 2 \\\n",
        "  --lr 0.01 \\\n",
        "  --output ./train_output \\\n",
        "  --automated_k \\\n",
        "  --curriculum \\\n",
        "  --CL_PHASE_EPOCHS 10 \\\n",
        "  --enable_shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "675almf945Qg",
        "outputId": "8dbf6254-bbaf-43dc-c5f9-59d0c587ae30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90300\n",
            "\tNumPy: 2.0.2\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm: diversify\n",
            "alpha: 1.0\n",
            "alpha1: 1.0\n",
            "batch_size: 32\n",
            "beta1: 0.5\n",
            "checkpoint_freq: 100\n",
            "local_epoch: 3\n",
            "max_epoch: 2\n",
            "lr: 0.01\n",
            "lr_decay1: 1.0\n",
            "lr_decay2: 1.0\n",
            "weight_decay: 0.0005\n",
            "bottleneck: 256\n",
            "classifier: linear\n",
            "dis_hidden: 256\n",
            "layer: bn\n",
            "model_size: median\n",
            "lam: 0.0\n",
            "latent_domain_num: 10\n",
            "domain_num: 0\n",
            "data_file: \n",
            "dataset: emg\n",
            "data_dir: ./data/\n",
            "task: cross_people\n",
            "test_envs: [0]\n",
            "N_WORKERS: 4\n",
            "automated_k: True\n",
            "curriculum: True\n",
            "CL_PHASE_EPOCHS: 10\n",
            "enable_shap: True\n",
            "resume: None\n",
            "gpu_id: 0\n",
            "seed: 0\n",
            "output: ./train_output\n",
            "old: False\n",
            "steps_per_epoch: 10000000000\n",
            "select_position: {'emg': [0]}\n",
            "select_channel: {'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list: {'emg': 1000}\n",
            "act_people: {'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "input_shape: (8, 1, 200)\n",
            "num_classes: 6\n",
            "grid_size: 10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Running automated K estimation...\n",
            "K=2: Silhouette=0.1779, DBI=5.5236, Combined=0.3711\n",
            "K=3: Silhouette=0.1550, DBI=4.9580, Combined=0.3727\n",
            "K=4: Silhouette=0.1382, DBI=4.6314, Combined=0.3733\n",
            "K=5: Silhouette=0.1278, DBI=4.4261, Combined=0.3741\n",
            "K=6: Silhouette=0.1233, DBI=4.3454, Combined=0.3744\n",
            "K=7: Silhouette=0.1156, DBI=4.2599, Combined=0.3740\n",
            "K=8: Silhouette=0.1192, DBI=4.1145, Combined=0.3776\n",
            "K=9: Silhouette=0.1154, DBI=4.0864, Combined=0.3772\n",
            "K=10: Silhouette=0.1191, DBI=4.0742, Combined=0.3783\n",
            "[INFO] Optimal K determined as 10 (Combined Score: 0.3783)\n",
            "Using automated latent_domain_num (K): 10\n",
            "Adjusted batch size: 160\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "======== ROUND 0 ========\n",
            "Curriculum learning: Stage 0 (using 10 epochs)\n",
            "Curriculum learning: Stage 0\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0000\n",
            "2. Domain 0.0: Difficulty = 0.2833\n",
            "3. Domain 2.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 2.0\n",
            "Selected 3314 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.666065        \n",
            "1                0.591846        \n",
            "2                0.557749        \n",
            "3                0.506235        \n",
            "4                0.414511        \n",
            "5                0.460348        \n",
            "6                0.489004        \n",
            "7                0.401937        \n",
            "8                0.297841        \n",
            "9                0.491667        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.996541         0.946710         0.049830        \n",
            "1                0.922915         0.915317         0.007598        \n",
            "2                0.697547         0.695362         0.002185        \n",
            "3                0.770208         0.769488         0.000720        \n",
            "4                1.335065         1.334465         0.000600        \n",
            "5                0.926293         0.925712         0.000580        \n",
            "6                0.892075         0.891431         0.000644        \n",
            "7                1.182417         1.181944         0.000473        \n",
            "8                1.665524         1.665033         0.000491        \n",
            "9                0.774569         0.774107         0.000461        \n",
            "Counter({np.int64(3): 3200})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.334204         0.242026         0.576230         0.849728         0.801932         0.690141         0.976496        \n",
            "1                0.325418         0.145063         0.470480         0.921243         0.852174         0.709507         0.954243        \n",
            "2                0.190659         0.218199         0.408858         0.935124         0.859903         0.718897         0.981070        \n",
            "3                0.197839         0.140202         0.338041         0.930597         0.861836         0.704812         1.496614        \n",
            "4                0.309750         0.210965         0.520715         0.909475         0.839614         0.709507         1.231342        \n",
            "5                0.172120         0.199140         0.371260         0.916415         0.850242         0.713615         0.939933        \n",
            "6                0.204835         0.184642         0.389476         0.911889         0.842512         0.658451         0.935006        \n",
            "7                0.228469         0.100643         0.329112         0.916717         0.848309         0.725939         0.955707        \n",
            "8                0.112680         0.174422         0.287103         0.943874         0.858937         0.689554         0.971318        \n",
            "9                0.202749         0.129831         0.332580         0.923657         0.842512         0.716549         0.961937        \n",
            "\n",
            "======== ROUND 1 ========\n",
            "Curriculum learning: Stage 1 (using 10 epochs)\n",
            "Curriculum learning: Stage 1\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 0.0: Difficulty = 0.0000\n",
            "2. Domain 2.0: Difficulty = 0.9135\n",
            "3. Domain 1.0: Difficulty = 0.9962\n",
            "Adding random harder domain: 1.0\n",
            "Selected 3314 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.972489        \n",
            "1                0.934881        \n",
            "2                0.801010        \n",
            "3                0.867630        \n",
            "4                0.912127        \n",
            "5                0.740942        \n",
            "6                0.707214        \n",
            "7                0.866670        \n",
            "8                0.814512        \n",
            "9                0.683981        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.178689         0.521317         0.657372        \n",
            "1                1.255071         0.684187         0.570883        \n",
            "2                1.269428         0.599739         0.669689        \n",
            "3                1.663563         1.089015         0.574548        \n",
            "4                1.417732         0.973650         0.444081        \n",
            "5                1.735653         1.177042         0.558611        \n",
            "6                1.679767         1.138546         0.541221        \n",
            "7                1.259324         0.781989         0.477335        \n",
            "8                2.344075         1.874681         0.469394        \n",
            "9                1.051011         0.560203         0.490807        \n",
            "Counter({np.int64(3): 803, np.int64(2): 512, np.int64(0): 427, np.int64(6): 343, np.int64(8): 237, np.int64(1): 227, np.int64(5): 214, np.int64(9): 204, np.int64(7): 146, np.int64(4): 87})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "10               0.297134         1.337614         1.634747         0.878998         0.759420         0.620305         0.938988        \n",
            "11               0.329115         1.148462         1.477576         0.906156         0.821256         0.651995         0.946194        \n",
            "12               0.196229         1.186637         1.382866         0.940253         0.820290         0.705986         0.936729        \n",
            "13               0.188673         1.076694         1.265367         0.915510         0.806763         0.669014         0.986815        \n",
            "14               0.178127         1.025009         1.203136         0.943573         0.823188         0.689554         0.957022        \n",
            "15               0.289023         1.287412         1.576436         0.902535         0.777778         0.664319         0.954064        \n",
            "16               0.192068         1.119499         1.311567         0.946590         0.811594         0.688380         0.951017        \n",
            "17               0.286542         1.331272         1.617814         0.762824         0.684058         0.569249         0.965791        \n",
            "18               0.085174         0.968065         1.053239         0.969523         0.818357         0.702465         0.957980        \n",
            "19               0.122847         1.184570         1.307417         0.975558         0.821256         0.688967         1.114554        \n",
            "\n",
            "🎯 Final Target Accuracy: 0.7048\n",
            "\n",
            "📊 Running SHAP explainability...\n",
            "⚠️ Shape mismatch: SHAP values (10, 9600) vs features (10, 1600)\n",
            "⚠️ Using truncated shapes: SHAP (10, 1600), features (10, 1600)\n",
            "✅ Saved summary plot: ./train_output/shap_summary.png\n",
            "✅ Saved signal overlay: ./train_output/shap_overlay.png\n",
            "✅ Saved SHAP heatmap: ./train_output/shap_heatmap.png\n",
            "✅ Saved SHAP values to: ./train_output/shap_values.npy\n",
            "[SHAP] Accuracy Drop: 0.0000\n",
            "[SHAP] Flip Rate: 0.0000\n",
            "[SHAP] Confidence Δ: 0.0450\n",
            "[SHAP] AOPC: 0.0045\n",
            "[SHAP] Entropy: 8.5639\n",
            "[SHAP] Coherence: 0.0283\n",
            "[SHAP] Channel Variance: 0.0008\n",
            "[SHAP] Temporal Entropy: 7.0488\n",
            "[SHAP] Mutual Info: 0.0301\n",
            "[SHAP] PCA Alignment: 0.5255\n",
            "[SHAP] Jaccard (top-10): 0.0526\n",
            "[SHAP] Kendall's Tau: 0.1870\n",
            "[SHAP] Cosine Similarity: 0.5432\n",
            "✅ Saved interactive 4D SHAP plot: ./train_output/shap_4d_scatter.html\n",
            "✅ Saved interactive SHAP surface plot: ./train_output/shap_4d_surface.html\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning:\n",
            "\n",
            "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n",
            "✅ SHAP analysis completed successfully\n",
            "✅ Training metrics plot saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --data_dir ./data/ \\\n",
        "  --task cross_people \\\n",
        "  --test_envs 1 \\\n",
        "  --dataset emg \\\n",
        "  --algorithm diversify \\\n",
        "  --alpha1 1.0 \\\n",
        "  --alpha 1.0 \\\n",
        "  --lam 0.0 \\\n",
        "  --local_epoch 3 \\\n",
        "  --max_epoch 6 \\\n",
        "  --lr 0.01 \\\n",
        "  --output ./train_output \\\n",
        "  --automated_k \\\n",
        "  --curriculum \\\n",
        "  --CL_PHASE_EPOCHS 6 \\\n",
        "  --enable_shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQgxaNKK8iyd",
        "outputId": "62253eb9-c021-4c0f-92ea-861f269dfc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90300\n",
            "\tNumPy: 2.0.2\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm: diversify\n",
            "alpha: 1.0\n",
            "alpha1: 1.0\n",
            "batch_size: 32\n",
            "beta1: 0.5\n",
            "checkpoint_freq: 100\n",
            "local_epoch: 3\n",
            "max_epoch: 6\n",
            "lr: 0.01\n",
            "lr_decay1: 1.0\n",
            "lr_decay2: 1.0\n",
            "weight_decay: 0.0005\n",
            "bottleneck: 256\n",
            "classifier: linear\n",
            "dis_hidden: 256\n",
            "layer: bn\n",
            "model_size: median\n",
            "lam: 0.0\n",
            "latent_domain_num: None\n",
            "domain_num: 0\n",
            "data_file: \n",
            "dataset: emg\n",
            "data_dir: ./data/\n",
            "task: cross_people\n",
            "test_envs: [1]\n",
            "N_WORKERS: 4\n",
            "automated_k: True\n",
            "curriculum: True\n",
            "CL_PHASE_EPOCHS: 6\n",
            "enable_shap: True\n",
            "resume: None\n",
            "gpu_id: 0\n",
            "seed: 0\n",
            "output: ./train_output\n",
            "old: False\n",
            "steps_per_epoch: 10000000000\n",
            "select_position: {'emg': [0]}\n",
            "select_channel: {'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list: {'emg': 1000}\n",
            "act_people: {'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "input_shape: (8, 1, 200)\n",
            "num_classes: 6\n",
            "grid_size: 10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Running automated K estimation...\n",
            "K=2: Silhouette=0.1890, DBI=5.4657, Combined=0.3746\n",
            "K=3: Silhouette=0.1604, DBI=5.0602, Combined=0.3726\n",
            "K=4: Silhouette=0.1539, DBI=4.6625, Combined=0.3768\n",
            "K=5: Silhouette=0.1393, DBI=4.4480, Combined=0.3766\n",
            "K=6: Silhouette=0.1360, DBI=4.4304, Combined=0.3761\n",
            "K=7: Silhouette=0.1198, DBI=4.2699, Combined=0.3748\n",
            "K=8: Silhouette=0.1208, DBI=4.1515, Combined=0.3773\n",
            "K=9: Silhouette=0.1187, DBI=4.1225, Combined=0.3773\n",
            "K=10: Silhouette=0.1181, DBI=3.7511, Combined=0.3848\n",
            "[INFO] Optimal K determined as 10 (Combined Score: 0.3848)\n",
            "Using automated latent_domain_num (K): 10\n",
            "Adjusted batch size: 160\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "======== ROUND 0 ========\n",
            "Curriculum learning: Stage 0 (using 6 epochs)\n",
            "Curriculum learning: Stage 0\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 0.0: Difficulty = 0.0014\n",
            "2. Domain 1.0: Difficulty = 0.0049\n",
            "3. Domain 2.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 2.0\n",
            "Selected 3244 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.892770        \n",
            "1                0.645208        \n",
            "2                0.618179        \n",
            "3                0.587151        \n",
            "4                0.348464        \n",
            "5                0.497752        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.860317         0.820551         0.039766        \n",
            "1                0.916232         0.909835         0.006397        \n",
            "2                0.740107         0.738214         0.001893        \n",
            "3                1.263114         1.262176         0.000938        \n",
            "4                0.647657         0.647057         0.000601        \n",
            "5                0.782593         0.782021         0.000572        \n",
            "Counter({np.int64(1): 3200})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.525397         0.135245         0.660642         0.827990         0.785785         0.778942         1.084368        \n",
            "1                0.460424         0.037843         0.498268         0.870530         0.812438         0.842889         1.517658        \n",
            "2                0.564859         0.143081         0.707940         0.845869         0.777887         0.814223         1.159334        \n",
            "3                0.329914         0.122418         0.452332         0.893958         0.839092         0.845094         0.961882        \n",
            "4                0.477751         0.016784         0.494535         0.858816         0.794669         0.791069         0.959937        \n",
            "5                0.472556         0.103340         0.575896         0.803021         0.745311         0.778390         0.946946        \n",
            "\n",
            "======== ROUND 1 ========\n",
            "Curriculum learning: Stage 1 (using 6 epochs)\n",
            "Curriculum learning: Stage 1\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 2.0: Difficulty = 0.1486\n",
            "2. Domain 1.0: Difficulty = 0.2493\n",
            "3. Domain 0.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 0.0\n",
            "Selected 3244 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                1.050130        \n",
            "1                1.133314        \n",
            "2                1.029943        \n",
            "3                1.125533        \n",
            "4                0.912385        \n",
            "5                0.981802        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.258594         0.717175         0.541420        \n",
            "1                1.335634         0.793324         0.542311        \n",
            "2                1.403663         0.871489         0.532174        \n",
            "3                1.459104         0.881055         0.578049        \n",
            "4                1.477498         1.020666         0.456831        \n",
            "5                1.308987         0.850837         0.458150        \n",
            "Counter({np.int64(6): 3200})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "6                0.304585         0.100456         0.405041         0.897041         0.835143         0.809813         0.992280        \n",
            "7                0.277728         0.121644         0.399372         0.902281         0.824284         0.839030         1.032290        \n",
            "8                0.396924         0.057391         0.454315         0.916153         0.830207         0.787762         1.492926        \n",
            "9                0.403372         0.058204         0.461576         0.889951         0.805528         0.819184         1.240459        \n",
            "10               0.142384         0.085760         0.228144         0.928792         0.818361         0.816428         0.972672        \n",
            "11               0.270764         0.167393         0.438157         0.933107         0.823297         0.813671         0.941869        \n",
            "\n",
            "======== ROUND 2 ========\n",
            "Curriculum learning: Stage 2 (using 6 epochs)\n",
            "Curriculum learning: Stage 2\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0000\n",
            "2. Domain 0.0: Difficulty = 0.5984\n",
            "3. Domain 2.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 2.0\n",
            "Selected 3244 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                1.016384        \n",
            "1                0.998236        \n",
            "2                1.238072        \n",
            "3                1.010243        \n",
            "4                1.040007        \n",
            "5                0.968795        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.414488         0.773984         0.640504        \n",
            "1                1.951101         1.298980         0.652121        \n",
            "2                1.533207         0.984791         0.548417        \n",
            "3                1.502177         0.697383         0.804794        \n",
            "4                1.206609         0.693398         0.513211        \n",
            "5                2.415380         1.750989         0.664392        \n",
            "Counter({np.int64(3): 3200})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "12               0.239195         0.122259         0.361454         0.918619         0.823297         0.819735         0.986516        \n",
            "13               0.156630         0.127737         0.284367         0.936806         0.827246         0.823043         0.987157        \n",
            "14               0.178777         0.069354         0.248131         0.945438         0.837117         0.818633         0.967853        \n",
            "15               0.125756         0.036979         0.162735         0.973798         0.839092         0.828556         1.460200        \n",
            "16               0.167873         0.094913         0.262786         0.932799         0.826259         0.807607         1.268570        \n",
            "17               0.128505         0.115168         0.243673         0.954377         0.835143         0.813120         0.965503        \n",
            "\n",
            "======== ROUND 3 ========\n",
            "Curriculum learning: Stage 3 (using 6 epochs)\n",
            "Curriculum learning: Stage 3\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0442\n",
            "2. Domain 0.0: Difficulty = 0.2080\n",
            "3. Domain 2.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 2.0\n",
            "Selected 3244 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                1.145028        \n",
            "1                1.036076        \n",
            "2                0.968962        \n",
            "3                0.907063        \n",
            "4                0.919588        \n",
            "5                0.766305        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.660362         0.923994         0.736368        \n",
            "1                1.897641         1.316212         0.581428        \n",
            "2                1.355186         0.803342         0.551844        \n",
            "3                1.461621         0.735547         0.726074        \n",
            "4                1.668566         0.958891         0.709674        \n",
            "5                1.799000         1.207839         0.591161        \n",
            "Counter({np.int64(6): 768, np.int64(1): 456, np.int64(0): 456, np.int64(4): 328, np.int64(2): 286, np.int64(3): 230, np.int64(9): 206, np.int64(7): 195, np.int64(8): 177, np.int64(5): 98})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "18               0.188650         1.407801         1.596451         0.931874         0.806515         0.824697         1.019209        \n",
            "19               0.179840         1.223856         1.403696         0.940197         0.806515         0.820838         1.006632        \n",
            "20               0.185266         1.446195         1.631461         0.969174         0.803554         0.813671         0.982685        \n",
            "21               0.126669         1.327427         1.454096         0.926634         0.793682         0.786108         0.963638        \n",
            "22               0.169082         1.314922         1.484004         0.965783         0.786772         0.779493         1.487590        \n",
            "23               0.302317         1.590850         1.893167         0.957152         0.780849         0.772326         1.234162        \n",
            "\n",
            "======== ROUND 4 ========\n",
            "Curriculum learning: Stage 4 (using 6 epochs)\n",
            "Curriculum learning: Stage 4\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 0.0: Difficulty = 0.0580\n",
            "2. Domain 1.0: Difficulty = 0.5331\n",
            "3. Domain 2.0: Difficulty = 1.0000\n",
            "Selected 3244 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                1.614715        \n",
            "1                1.355563        \n",
            "2                1.495195        \n",
            "3                1.057268        \n",
            "4                0.872695        \n",
            "5                0.801196        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.294657         0.911537         1.383119        \n",
            "1                1.704384         0.747022         0.957361        \n",
            "2                1.791847         0.850619         0.941228        \n",
            "3                1.883348         0.934220         0.949128        \n",
            "4                1.857341         0.868509         0.988832        \n",
            "5                1.843470         0.965061         0.878409        \n",
            "Counter({np.int64(6): 602, np.int64(0): 412, np.int64(1): 370, np.int64(4): 331, np.int64(3): 300, np.int64(2): 269, np.int64(9): 256, np.int64(5): 231, np.int64(8): 223, np.int64(7): 206})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "24               0.257020         1.382067         1.639087         0.947596         0.802567         0.808710         0.996158        \n",
            "25               0.172868         1.279719         1.452587         0.936498         0.771964         0.773980         0.983254        \n",
            "26               0.285471         1.340951         1.626422         0.751233         0.634748         0.624587         0.973918        \n",
            "27               0.166888         1.277959         1.444847         0.898274         0.748272         0.746968         0.954753        \n",
            "28               0.220019         1.364688         1.584707         0.909679         0.740375         0.746417         0.975191        \n",
            "29               0.140483         1.123625         1.264107         0.939889         0.763080         0.781147         1.489690        \n",
            "\n",
            "======== ROUND 5 ========\n",
            "Curriculum learning: Stage 5 (using 6 epochs)\n",
            "Curriculum learning: Stage 5\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 0.0: Difficulty = 0.0000\n",
            "2. Domain 2.0: Difficulty = 0.7557\n",
            "3. Domain 1.0: Difficulty = 0.8980\n",
            "Selected 3244 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                1.281053        \n",
            "1                0.949080        \n",
            "2                0.659963        \n",
            "3                0.730157        \n",
            "4                0.493306        \n",
            "5                0.443180        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.608597         0.879913         0.728684        \n",
            "1                1.413861         0.769761         0.644099        \n",
            "2                2.065861         1.136732         0.929129        \n",
            "3                2.151830         1.168382         0.983449        \n",
            "4                1.460907         0.854779         0.606128        \n",
            "5                1.400968         0.915032         0.485935        \n",
            "Counter({np.int64(6): 585, np.int64(0): 402, np.int64(4): 344, np.int64(1): 316, np.int64(5): 285, np.int64(9): 282, np.int64(3): 278, np.int64(2): 257, np.int64(7): 235, np.int64(8): 216})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "30               0.401397         1.458541         1.859938         0.963625         0.797631         0.782249         0.982186        \n",
            "31               0.200995         1.310118         1.511113         0.950062         0.773939         0.767365         0.994209        \n",
            "32               0.136097         1.208521         1.344618         0.956535         0.784798         0.756340         0.977396        \n",
            "33               0.145031         1.259187         1.404218         0.962084         0.788746         0.750276         0.969077        \n",
            "34               0.201732         1.599566         1.801298         0.828607         0.685094         0.625138         0.965509        \n",
            "35               0.136112         1.345613         1.481724         0.959618         0.769003         0.735391         0.967370        \n",
            "\n",
            "🎯 Final Target Accuracy: 0.8451\n",
            "\n",
            "📊 Running SHAP explainability...\n",
            "⚠️ Shape mismatch: SHAP values (10, 9600) vs features (10, 1600)\n",
            "⚠️ Using truncated shapes: SHAP (10, 1600), features (10, 1600)\n",
            "✅ Saved summary plot: ./train_output/shap_summary.png\n",
            "✅ Saved signal overlay: ./train_output/shap_overlay.png\n",
            "✅ Saved SHAP heatmap: ./train_output/shap_heatmap.png\n",
            "✅ Saved SHAP values to: ./train_output/shap_values.npy\n",
            "[SHAP] Accuracy Drop: 70.0000\n",
            "[SHAP] Flip Rate: 0.7000\n",
            "[SHAP] Confidence Δ: 0.0650\n",
            "[SHAP] AOPC: 0.0065\n",
            "[SHAP] Entropy: 8.6005\n",
            "[SHAP] Coherence: 0.0300\n",
            "[SHAP] Channel Variance: 0.0009\n",
            "[SHAP] Temporal Entropy: 7.0592\n",
            "[SHAP] Mutual Info: 0.0140\n",
            "[SHAP] PCA Alignment: 0.4493\n",
            "[SHAP] Jaccard (top-10): 0.0000\n",
            "[SHAP] Kendall's Tau: 0.1281\n",
            "[SHAP] Cosine Similarity: 0.4159\n",
            "✅ Saved interactive 4D SHAP plot: ./train_output/shap_4d_scatter.html\n",
            "✅ Saved interactive SHAP surface plot: ./train_output/shap_4d_surface.html\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning:\n",
            "\n",
            "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n",
            "✅ SHAP analysis completed successfully\n",
            "✅ Training metrics plot saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --data_dir ./data/ \\\n",
        "  --task cross_people \\\n",
        "  --test_envs 2 \\\n",
        "  --dataset emg \\\n",
        "  --algorithm diversify \\\n",
        "  --alpha1 0.5 \\\n",
        "  --alpha 1.0 \\\n",
        "  --lam 0.0 \\\n",
        "  --local_epoch 3 \\\n",
        "  --max_epoch 6 \\\n",
        "  --lr 0.01 \\\n",
        "  --output ./train_output \\\n",
        "  --automated_k \\\n",
        "  --curriculum \\\n",
        "  --CL_PHASE_EPOCHS 10 \\\n",
        "  --enable_shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaG3NHS847-9",
        "outputId": "c9772d73-88bd-4aae-ec8a-37c91b48a618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90300\n",
            "\tNumPy: 2.0.2\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm: diversify\n",
            "alpha: 1.0\n",
            "alpha1: 0.5\n",
            "batch_size: 32\n",
            "beta1: 0.5\n",
            "checkpoint_freq: 100\n",
            "local_epoch: 3\n",
            "max_epoch: 6\n",
            "lr: 0.01\n",
            "lr_decay1: 1.0\n",
            "lr_decay2: 1.0\n",
            "weight_decay: 0.0005\n",
            "bottleneck: 256\n",
            "classifier: linear\n",
            "dis_hidden: 256\n",
            "layer: bn\n",
            "model_size: median\n",
            "lam: 0.0\n",
            "latent_domain_num: None\n",
            "domain_num: 0\n",
            "data_file: \n",
            "dataset: emg\n",
            "data_dir: ./data/\n",
            "task: cross_people\n",
            "test_envs: [2]\n",
            "N_WORKERS: 4\n",
            "automated_k: True\n",
            "curriculum: True\n",
            "CL_PHASE_EPOCHS: 10\n",
            "enable_shap: True\n",
            "resume: None\n",
            "gpu_id: 0\n",
            "seed: 0\n",
            "output: ./train_output\n",
            "old: False\n",
            "steps_per_epoch: 10000000000\n",
            "select_position: {'emg': [0]}\n",
            "select_channel: {'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list: {'emg': 1000}\n",
            "act_people: {'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "input_shape: (8, 1, 200)\n",
            "num_classes: 6\n",
            "grid_size: 10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Running automated K estimation...\n",
            "K=2: Silhouette=0.1726, DBI=5.4903, Combined=0.3702\n",
            "K=3: Silhouette=0.1588, DBI=4.9649, Combined=0.3735\n",
            "K=4: Silhouette=0.1473, DBI=4.5667, Combined=0.3766\n",
            "K=5: Silhouette=0.1399, DBI=4.4556, Combined=0.3766\n",
            "K=6: Silhouette=0.1261, DBI=4.2984, Combined=0.3759\n",
            "K=7: Silhouette=0.1193, DBI=4.2549, Combined=0.3750\n",
            "K=8: Silhouette=0.1166, DBI=4.1249, Combined=0.3767\n",
            "K=9: Silhouette=0.1133, DBI=4.0861, Combined=0.3766\n",
            "K=10: Silhouette=0.1051, DBI=4.0684, Combined=0.3749\n",
            "[INFO] Optimal K determined as 8 (Combined Score: 0.3767)\n",
            "Using automated latent_domain_num (K): 8\n",
            "Adjusted batch size: 128\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "======== ROUND 0 ========\n",
            "Curriculum learning: Stage 0 (using 10 epochs)\n",
            "Curriculum learning: Stage 0\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0000\n",
            "2. Domain 0.0: Difficulty = 0.6919\n",
            "3. Domain 2.0: Difficulty = 0.9087\n",
            "Adding random harder domain: 2.0\n",
            "Selected 3334 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.956495        \n",
            "1                0.685933        \n",
            "2                0.591205        \n",
            "3                0.477150        \n",
            "4                0.580694        \n",
            "5                0.536146        \n",
            "6                0.375358        \n",
            "7                0.462285        \n",
            "8                0.244971        \n",
            "9                0.327982        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.788123         0.762207         0.025916        \n",
            "1                1.333274         1.329890         0.003384        \n",
            "2                1.279745         1.278841         0.000903        \n",
            "3                1.407829         1.407176         0.000653        \n",
            "4                0.769730         0.769177         0.000553        \n",
            "5                1.640992         1.640599         0.000393        \n",
            "6                1.323139         1.322584         0.000556        \n",
            "7                0.612799         0.612336         0.000463        \n",
            "8                1.067819         1.067356         0.000463        \n",
            "9                0.822843         0.822390         0.000453        \n",
            "Counter({np.int64(2): 3328})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.492480         0.068931         0.561411         0.827235         0.780230         0.725478         1.666535        \n",
            "1                0.257088         0.001264         0.258352         0.915417         0.866603         0.786483         1.159469        \n",
            "2                0.346660         0.003299         0.349959         0.857229         0.809981         0.738636         1.156416        \n",
            "3                0.448820         0.000837         0.449657         0.926815         0.864683         0.764354         1.061413        \n",
            "4                0.231879         0.000642         0.232521         0.871626         0.804223         0.755981         1.057693        \n",
            "5                0.127631         0.000746         0.128377         0.917217         0.833973         0.767344         1.076668        \n",
            "6                0.185846         0.001714         0.187559         0.960708         0.862764         0.784689         1.072196        \n",
            "7                0.267713         0.002527         0.270239         0.915117         0.811900         0.754785         1.080701        \n",
            "8                0.214690         0.001063         0.215752         0.931314         0.830134         0.775718         1.076391        \n",
            "9                0.170470         0.000656         0.171126         0.961608         0.876200         0.798445         1.053964        \n",
            "\n",
            "======== ROUND 1 ========\n",
            "Curriculum learning: Stage 1 (using 10 epochs)\n",
            "Curriculum learning: Stage 1\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0000\n",
            "2. Domain 2.0: Difficulty = 0.6234\n",
            "3. Domain 0.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 0.0\n",
            "Selected 3334 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.758544        \n",
            "1                0.878970        \n",
            "2                0.879198        \n",
            "3                0.815604        \n",
            "4                0.705626        \n",
            "5                0.759018        \n",
            "6                0.578580        \n",
            "7                0.689618        \n",
            "8                0.713670        \n",
            "9                0.556422        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.276818         0.683491         0.593327        \n",
            "1                1.633570         1.138941         0.494629        \n",
            "2                1.121734         0.661376         0.460358        \n",
            "3                1.452839         0.940562         0.512276        \n",
            "4                1.654704         1.091827         0.562877        \n",
            "5                1.187282         0.727871         0.459411        \n",
            "6                1.271276         0.809363         0.461913        \n",
            "7                1.512313         1.040581         0.471732        \n",
            "8                1.140560         0.727218         0.413342        \n",
            "9                1.472438         0.982746         0.489692        \n",
            "Counter({np.int64(2): 1321, np.int64(0): 390, np.int64(7): 348, np.int64(4): 327, np.int64(6): 303, np.int64(1): 239, np.int64(3): 222, np.int64(5): 178})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "10               0.457942         1.416932         1.874874         0.799340         0.716891         0.679426         1.084366        \n",
            "11               0.623516         1.361959         1.985475         0.848830         0.761996         0.688397         1.078596        \n",
            "12               0.231015         1.220597         1.451612         0.896521         0.815739         0.703349         1.081389        \n",
            "13               0.249531         0.960996         1.210527         0.970906         0.853167         0.748804         1.470057        \n",
            "14               0.148574         1.074394         1.222968         0.936413         0.816699         0.703947         1.534142        \n",
            "15               0.260008         1.353835         1.613843         0.936413         0.800384         0.716507         1.074947        \n",
            "16               0.234438         0.991302         1.225740         0.949610         0.836852         0.744019         1.087098        \n",
            "17               0.207546         1.080493         1.288040         0.949610         0.820537         0.737440         1.096117        \n",
            "18               0.296294         1.220534         1.516828         0.971506         0.833013         0.748206         1.108012        \n",
            "19               0.172175         0.822712         0.994887         0.970906         0.848369         0.753589         1.099118        \n",
            "\n",
            "======== ROUND 2 ========\n",
            "Curriculum learning: Stage 2 (using 10 epochs)\n",
            "Curriculum learning: Stage 2\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0000\n",
            "2. Domain 2.0: Difficulty = 0.5920\n",
            "3. Domain 0.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 0.0\n",
            "Selected 3334 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                1.322469        \n",
            "1                1.030975        \n",
            "2                0.937787        \n",
            "3                1.332920        \n",
            "4                0.815362        \n",
            "5                0.679631        \n",
            "6                0.537033        \n",
            "7                0.567097        \n",
            "8                0.434577        \n",
            "9                0.466941        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.672384         0.688969         0.983415        \n",
            "1                1.620153         0.972755         0.647398        \n",
            "2                1.510235         0.757517         0.752718        \n",
            "3                1.861255         1.090534         0.770721        \n",
            "4                1.505943         0.925084         0.580859        \n",
            "5                1.668388         1.010015         0.658373        \n",
            "6                1.462702         0.953785         0.508917        \n",
            "7                1.529206         1.008503         0.520703        \n",
            "8                1.243394         0.850599         0.392795        \n",
            "9                1.268950         0.879900         0.389050        \n",
            "Counter({np.int64(2): 1080, np.int64(4): 486, np.int64(0): 371, np.int64(7): 354, np.int64(6): 318, np.int64(3): 264, np.int64(5): 242, np.int64(1): 213})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "20               0.287832         1.195809         1.483640         0.890222         0.760077         0.657297         1.074236        \n",
            "21               0.278583         1.260999         1.539582         0.951110         0.809021         0.721292         1.081996        \n",
            "22               0.197646         1.050847         1.248494         0.974505         0.810940         0.736842         1.140460        \n",
            "23               0.161841         1.237216         1.399057         0.956209         0.789827         0.724880         1.069141        \n",
            "24               0.163176         1.210186         1.373362         0.963707         0.797505         0.714713         1.051354        \n",
            "25               0.172660         1.249612         1.422272         0.847331         0.675624         0.586722         1.088929        \n",
            "26               0.174049         1.280650         1.454700         0.973305         0.811900         0.726077         1.063593        \n",
            "27               0.240667         1.314650         1.555317         0.964007         0.806142         0.714115         1.568772        \n",
            "28               0.137852         1.152536         1.290388         0.961608         0.785029         0.696770         1.365299        \n",
            "29               0.067912         1.194227         1.262139         0.986203         0.793666         0.720694         1.084722        \n",
            "\n",
            "======== ROUND 3 ========\n",
            "Curriculum learning: Stage 3 (using 10 epochs)\n",
            "Curriculum learning: Stage 3\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 2.0: Difficulty = 0.0000\n",
            "2. Domain 0.0: Difficulty = 0.7532\n",
            "3. Domain 1.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 1.0\n",
            "Selected 3334 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.907487        \n",
            "1                0.712872        \n",
            "2                0.620182        \n",
            "3                0.510751        \n",
            "4                0.308149        \n",
            "5                0.261594        \n",
            "6                0.455931        \n",
            "7                0.417467        \n",
            "8                0.439266        \n",
            "9                0.366126        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.507027         0.884942         0.622085        \n",
            "1                1.559362         0.994289         0.565074        \n",
            "2                1.667159         1.036781         0.630379        \n",
            "3                1.236637         0.913628         0.323008        \n",
            "4                1.151189         0.817576         0.333613        \n",
            "5                1.739137         1.404529         0.334608        \n",
            "6                1.107886         0.891195         0.216690        \n",
            "7                0.933901         0.785024         0.148877        \n",
            "8                1.448535         1.128671         0.319864        \n",
            "9                1.320958         1.071403         0.249555        \n",
            "Counter({np.int64(2): 1123, np.int64(4): 470, np.int64(0): 395, np.int64(6): 351, np.int64(7): 319, np.int64(3): 244, np.int64(5): 225, np.int64(1): 201})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "30               0.217546         1.072675         1.290221         0.972705         0.806142         0.735048         1.514630        \n",
            "31               0.090471         1.229639         1.320111         0.940312         0.765835         0.703947         1.472724        \n",
            "32               0.097324         1.276141         1.373465         0.984103         0.806142         0.741029         1.087000        \n",
            "33               0.057714         1.187294         1.245008         0.973305         0.797505         0.709928         1.070852        \n",
            "34               0.175346         1.260934         1.436280         0.963707         0.780230         0.706938         1.072009        \n",
            "35               0.108721         1.234192         1.342913         0.979604         0.789827         0.724282         1.067922        \n",
            "36               0.142094         1.247631         1.389725         0.977205         0.770633         0.693182         1.061393        \n",
            "37               0.092537         1.267683         1.360220         0.981404         0.786948         0.727273         1.069709        \n",
            "38               0.137628         1.180962         1.318590         0.984103         0.787908         0.718301         1.050426        \n",
            "39               0.178517         1.249786         1.428303         0.966407         0.761996         0.686603         1.061686        \n",
            "\n",
            "======== ROUND 4 ========\n",
            "Curriculum learning: Stage 4 (using 10 epochs)\n",
            "Curriculum learning: Stage 4\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 2.0: Difficulty = 0.0000\n",
            "2. Domain 0.0: Difficulty = 0.3604\n",
            "3. Domain 1.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 1.0\n",
            "Selected 3334 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.586076        \n",
            "1                0.570755        \n",
            "2                0.372750        \n",
            "3                0.464620        \n",
            "4                0.258059        \n",
            "5                0.270778        \n",
            "6                0.316593        \n",
            "7                0.212444        \n",
            "8                0.219225        \n",
            "9                0.286310        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.492961         0.904864         0.588097        \n",
            "1                1.642161         0.988644         0.653517        \n",
            "2                1.307863         0.975455         0.332408        \n",
            "3                1.484784         1.081810         0.402973        \n",
            "4                1.356916         1.055865         0.301051        \n",
            "5                1.321273         0.999260         0.322014        \n",
            "6                1.294629         1.105405         0.189223        \n",
            "7                1.119288         0.929326         0.189963        \n",
            "8                1.031193         0.921700         0.109493        \n",
            "9                1.166278         0.946253         0.220025        \n",
            "Counter({np.int64(2): 1106, np.int64(4): 472, np.int64(0): 401, np.int64(6): 381, np.int64(7): 316, np.int64(3): 237, np.int64(5): 225, np.int64(1): 190})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "40               0.261287         1.536997         1.798284         0.958908         0.791747         0.719498         1.062043        \n",
            "41               0.119240         1.195792         1.315032         0.968806         0.792706         0.697368         1.060780        \n",
            "42               0.100436         1.385325         1.485760         0.978404         0.792706         0.721890         1.065589        \n",
            "43               0.087815         1.395058         1.482873         0.981404         0.801344         0.729067         1.111913        \n",
            "44               0.063958         1.299086         1.363044         0.931314         0.772553         0.690191         1.672164        \n",
            "45               0.113754         1.415281         1.529035         0.969706         0.775432         0.677033         1.238941        \n",
            "46               0.072887         1.372225         1.445112         0.951710         0.758157         0.702751         1.080793        \n",
            "47               0.145244         1.374965         1.520209         0.961908         0.771593         0.668660         1.073520        \n",
            "48               0.170034         1.394148         1.564182         0.994301         0.804223         0.718301         1.072755        \n",
            "49               0.097442         1.259465         1.356906         0.965807         0.760077         0.677033         1.068208        \n",
            "\n",
            "======== ROUND 5 ========\n",
            "Curriculum learning: Stage 5 (using 10 epochs)\n",
            "Curriculum learning: Stage 5\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 2.0: Difficulty = 0.1308\n",
            "2. Domain 1.0: Difficulty = 0.6560\n",
            "3. Domain 0.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 0.0\n",
            "Selected 3334 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.655465        \n",
            "1                0.365854        \n",
            "2                0.267838        \n",
            "3                0.203266        \n",
            "4                0.354096        \n",
            "5                0.241779        \n",
            "6                0.194329        \n",
            "7                0.101550        \n",
            "8                0.182499        \n",
            "9                0.189530        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.213537         0.844298         0.369239        \n",
            "1                1.061345         0.865024         0.196321        \n",
            "2                1.302275         1.081930         0.220345        \n",
            "3                1.202849         1.008674         0.194175        \n",
            "4                1.198163         0.983855         0.214308        \n",
            "5                1.198726         1.047701         0.151026        \n",
            "6                1.221536         1.098483         0.123052        \n",
            "7                1.104728         0.967733         0.136995        \n",
            "8                1.026148         0.972442         0.053706        \n",
            "9                1.063202         0.996947         0.066255        \n",
            "Counter({np.int64(2): 1080, np.int64(4): 465, np.int64(0): 404, np.int64(6): 392, np.int64(7): 319, np.int64(5): 242, np.int64(3): 233, np.int64(1): 193})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "50               0.269589         1.283280         1.552869         0.978104         0.822457         0.732656         1.075193        \n",
            "51               0.071158         1.369638         1.440796         0.972106         0.779271         0.721890         1.089459        \n",
            "52               0.145030         1.218964         1.363994         0.976905         0.785988         0.687799         1.082278        \n",
            "53               0.070168         1.071786         1.141954         0.965507         0.794626         0.691388         1.068269        \n",
            "54               0.153992         1.554364         1.708356         0.942112         0.766795         0.683612         1.060321        \n",
            "55               0.197873         1.274705         1.472578         0.988902         0.799424         0.697368         1.083201        \n",
            "56               0.104649         1.344205         1.448854         0.988902         0.805182         0.711722         1.086454        \n",
            "57               0.044660         1.340773         1.385433         0.970606         0.780230         0.707536         1.354791        \n",
            "58               0.053157         1.267979         1.321136         0.979904         0.788868         0.686603         1.600538        \n",
            "59               0.072772         1.284726         1.357498         0.990402         0.793666         0.695574         1.127951        \n",
            "\n",
            "🎯 Final Target Accuracy: 0.7984\n",
            "\n",
            "📊 Running SHAP explainability...\n",
            "⚠️ Shape mismatch: SHAP values (10, 9600) vs features (10, 1600)\n",
            "⚠️ Using truncated shapes: SHAP (10, 1600), features (10, 1600)\n",
            "✅ Saved summary plot: ./train_output/shap_summary.png\n",
            "✅ Saved signal overlay: ./train_output/shap_overlay.png\n",
            "✅ Saved SHAP heatmap: ./train_output/shap_heatmap.png\n",
            "✅ Saved SHAP values to: ./train_output/shap_values.npy\n",
            "[SHAP] Accuracy Drop: 50.0000\n",
            "[SHAP] Flip Rate: 0.5000\n",
            "[SHAP] Confidence Δ: -0.0174\n",
            "[SHAP] AOPC: -0.0017\n",
            "[SHAP] Entropy: 8.5778\n",
            "[SHAP] Coherence: 0.0253\n",
            "[SHAP] Channel Variance: 0.0020\n",
            "[SHAP] Temporal Entropy: 7.0573\n",
            "[SHAP] Mutual Info: 0.0144\n",
            "[SHAP] PCA Alignment: 0.6185\n",
            "[SHAP] Jaccard (top-10): 0.0000\n",
            "[SHAP] Kendall's Tau: 0.1722\n",
            "[SHAP] Cosine Similarity: 0.5084\n",
            "✅ Saved interactive 4D SHAP plot: ./train_output/shap_4d_scatter.html\n",
            "✅ Saved interactive SHAP surface plot: ./train_output/shap_4d_surface.html\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning:\n",
            "\n",
            "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n",
            "✅ SHAP analysis completed successfully\n",
            "✅ Training metrics plot saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --data_dir ./data/ \\\n",
        "  --task cross_people \\\n",
        "  --test_envs 3 \\\n",
        "  --dataset emg \\\n",
        "  --algorithm diversify \\\n",
        "  --alpha1 5.0 \\\n",
        "  --alpha 0.1 \\\n",
        "  --lam 0.0 \\\n",
        "  --local_epoch 3 \\\n",
        "  --max_epoch 6 \\\n",
        "  --lr 0.01 \\\n",
        "  --output ./train_output \\\n",
        "  --automated_k \\\n",
        "  --curriculum \\\n",
        "  --CL_PHASE_EPOCHS 10 \\\n",
        "  --enable_shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJkWCD986VGo",
        "outputId": "49db7336-c45b-4e01-e51b-c140fb66efae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90300\n",
            "\tNumPy: 2.0.2\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm: diversify\n",
            "alpha: 0.1\n",
            "alpha1: 5.0\n",
            "batch_size: 32\n",
            "beta1: 0.5\n",
            "checkpoint_freq: 100\n",
            "local_epoch: 3\n",
            "max_epoch: 6\n",
            "lr: 0.01\n",
            "lr_decay1: 1.0\n",
            "lr_decay2: 1.0\n",
            "weight_decay: 0.0005\n",
            "bottleneck: 256\n",
            "classifier: linear\n",
            "dis_hidden: 256\n",
            "layer: bn\n",
            "model_size: median\n",
            "lam: 0.0\n",
            "latent_domain_num: None\n",
            "domain_num: 0\n",
            "data_file: \n",
            "dataset: emg\n",
            "data_dir: ./data/\n",
            "task: cross_people\n",
            "test_envs: [3]\n",
            "N_WORKERS: 4\n",
            "automated_k: True\n",
            "curriculum: True\n",
            "CL_PHASE_EPOCHS: 10\n",
            "enable_shap: True\n",
            "resume: None\n",
            "gpu_id: 0\n",
            "seed: 0\n",
            "output: ./train_output\n",
            "old: False\n",
            "steps_per_epoch: 10000000000\n",
            "select_position: {'emg': [0]}\n",
            "select_channel: {'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list: {'emg': 1000}\n",
            "act_people: {'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "input_shape: (8, 1, 200)\n",
            "num_classes: 6\n",
            "grid_size: 10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Running automated K estimation...\n",
            "K=2: Silhouette=0.1754, DBI=5.5434, Combined=0.3703\n",
            "K=3: Silhouette=0.1551, DBI=5.0284, Combined=0.3717\n",
            "K=4: Silhouette=0.1355, DBI=4.7182, Combined=0.3713\n",
            "K=5: Silhouette=0.1210, DBI=4.4833, Combined=0.3714\n",
            "K=6: Silhouette=0.1209, DBI=4.2830, Combined=0.3749\n",
            "K=7: Silhouette=0.1150, DBI=4.3045, Combined=0.3730\n",
            "K=8: Silhouette=0.1085, DBI=4.2494, Combined=0.3724\n",
            "K=9: Silhouette=0.1013, DBI=4.2172, Combined=0.3712\n",
            "K=10: Silhouette=0.0894, DBI=4.2131, Combined=0.3683\n",
            "[INFO] Optimal K determined as 6 (Combined Score: 0.3749)\n",
            "Using automated latent_domain_num (K): 6\n",
            "Adjusted batch size: 96\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "======== ROUND 0 ========\n",
            "Curriculum learning: Stage 0 (using 10 epochs)\n",
            "Curriculum learning: Stage 0\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 0.0: Difficulty = 0.0000\n",
            "2. Domain 1.0: Difficulty = 0.5330\n",
            "3. Domain 2.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 2.0\n",
            "Selected 3320 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                1.096584        \n",
            "1                0.668009        \n",
            "2                0.669687        \n",
            "3                0.559649        \n",
            "4                0.540800        \n",
            "5                0.551815        \n",
            "6                0.489351        \n",
            "7                0.319144        \n",
            "8                0.311489        \n",
            "9                0.490359        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.819619         0.810628         0.008992        \n",
            "1                0.543756         0.542706         0.001050        \n",
            "2                0.718558         0.718093         0.000465        \n",
            "3                0.565853         0.565393         0.000460        \n",
            "4                0.859307         0.858788         0.000519        \n",
            "5                0.879350         0.878870         0.000480        \n",
            "6                0.759853         0.759363         0.000490        \n",
            "7                0.619266         0.618793         0.000473        \n",
            "8                1.318374         1.317924         0.000450        \n",
            "9                1.116072         1.115641         0.000431        \n",
            "Counter({np.int64(0): 1372, np.int64(1): 627, np.int64(2): 498, np.int64(3): 476, np.int64(5): 197, np.int64(4): 94})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.341654         0.613764         0.955417         0.902410         0.849711         0.775546         1.184532        \n",
            "1                0.178121         0.792176         0.970297         0.889759         0.850674         0.779090         1.236140        \n",
            "2                0.259898         0.700462         0.960360         0.915964         0.847784         0.764324         1.201200        \n",
            "3                0.200253         0.718833         0.919086         0.931627         0.861272         0.788541         1.163536        \n",
            "4                0.330151         0.715449         1.045600         0.896687         0.834297         0.766686         1.172647        \n",
            "5                0.583122         0.730971         1.314093         0.921988         0.859345         0.770821         1.171215        \n",
            "6                0.224078         0.840330         1.064408         0.920783         0.854528         0.779090         1.168069        \n",
            "7                0.311541         0.717462         1.029003         0.937651         0.839114         0.753101         1.432793        \n",
            "8                0.297451         0.638761         0.936212         0.932229         0.834297         0.774956         1.678643        \n",
            "9                0.124847         0.637152         0.761999         0.903614         0.813102         0.733018         1.183672        \n",
            "\n",
            "======== ROUND 1 ========\n",
            "Curriculum learning: Stage 1 (using 10 epochs)\n",
            "Curriculum learning: Stage 1\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0000\n",
            "2. Domain 0.0: Difficulty = 0.8510\n",
            "3. Domain 2.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 2.0\n",
            "Selected 3320 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                1.048819        \n",
            "1                0.970875        \n",
            "2                0.900547        \n",
            "3                0.867511        \n",
            "4                0.819266        \n",
            "5                0.663171        \n",
            "6                0.816787        \n",
            "7                0.709703        \n",
            "8                0.671725        \n",
            "9                0.685162        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.109643         0.702088         1.407555        \n",
            "1                2.067034         1.269905         0.797129        \n",
            "2                1.783390         1.005169         0.778221        \n",
            "3                2.219534         1.655482         0.564052        \n",
            "4                1.649287         1.085664         0.563623        \n",
            "5                1.589058         0.896727         0.692331        \n",
            "6                1.205267         0.681782         0.523485        \n",
            "7                1.197903         0.694173         0.503730        \n",
            "8                1.796948         1.136299         0.660649        \n",
            "9                1.269096         0.851548         0.417548        \n",
            "Counter({np.int64(1): 741, np.int64(2): 694, np.int64(0): 615, np.int64(3): 529, np.int64(5): 469, np.int64(4): 216})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "10               0.190835         0.732553         0.923388         0.923795         0.836224         0.792676         1.538767        \n",
            "11               0.214519         0.766979         0.981497         0.922590         0.820809         0.740697         1.192592        \n",
            "12               0.210168         0.585985         0.796153         0.956627         0.861272         0.776728         1.200238        \n",
            "13               0.197278         0.782441         0.979719         0.954217         0.852601         0.763142         1.182601        \n",
            "14               0.142979         0.611365         0.754344         0.964157         0.851638         0.764324         1.176564        \n",
            "15               0.200361         0.981652         1.182013         0.945783         0.834297         0.736562         1.191077        \n",
            "16               0.218078         0.780880         0.998958         0.953614         0.820809         0.758417         1.185547        \n",
            "17               0.246008         0.875716         1.121724         0.972892         0.849711         0.763142         1.187385        \n",
            "18               0.063749         0.709499         0.773248         0.956024         0.823699         0.761961         1.282784        \n",
            "19               0.296929         0.672682         0.969611         0.962952         0.837187         0.747194         1.752490        \n",
            "\n",
            "======== ROUND 2 ========\n",
            "Curriculum learning: Stage 2 (using 10 epochs)\n",
            "Curriculum learning: Stage 2\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0000\n",
            "2. Domain 2.0: Difficulty = 0.9360\n",
            "3. Domain 0.0: Difficulty = 0.9818\n",
            "Adding random harder domain: 0.0\n",
            "Selected 3320 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.757778        \n",
            "1                0.865458        \n",
            "2                0.767281        \n",
            "3                0.920716        \n",
            "4                0.741819        \n",
            "5                0.667255        \n",
            "6                0.505557        \n",
            "7                0.672884        \n",
            "8                0.307507        \n",
            "9                0.489115        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.274194         1.142177         1.132017        \n",
            "1                1.699328         0.820306         0.879021        \n",
            "2                1.392969         0.725157         0.667812        \n",
            "3                1.861556         1.098687         0.762869        \n",
            "4                1.718679         1.046830         0.671849        \n",
            "5                1.398504         0.733595         0.664908        \n",
            "6                1.364421         0.781634         0.582787        \n",
            "7                1.965207         1.000399         0.964808        \n",
            "8                2.716301         1.416033         1.300268        \n",
            "9                1.353608         0.777816         0.575792        \n",
            "Counter({np.int64(2): 688, np.int64(3): 642, np.int64(1): 599, np.int64(5): 592, np.int64(0): 480, np.int64(4): 263})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "20               0.125308         0.695405         0.820713         0.966566         0.849711         0.780862         1.430674        \n",
            "21               0.144136         0.861608         1.005744         0.944578         0.840077         0.729474         1.727559        \n",
            "22               0.160435         0.684717         0.845152         0.981928         0.870906         0.775546         1.199692        \n",
            "23               0.126999         0.977928         1.104928         0.973795         0.852601         0.757826         1.160334        \n",
            "24               0.172056         0.783125         0.955181         0.971988         0.840077         0.762552         1.162827        \n",
            "25               0.160152         0.684547         0.844699         0.982229         0.845857         0.776137         1.193159        \n",
            "26               0.150061         0.783968         0.934030         0.970181         0.849711         0.734790         1.187958        \n",
            "27               0.071412         1.010205         1.081617         0.984639         0.850674         0.760780         1.199917        \n",
            "28               0.047849         0.705918         0.753768         0.984940         0.854528         0.769049         1.199715        \n",
            "29               0.072727         0.834918         0.907646         0.946988         0.822736         0.748376         1.200293        \n",
            "\n",
            "======== ROUND 3 ========\n",
            "Curriculum learning: Stage 3 (using 10 epochs)\n",
            "Curriculum learning: Stage 3\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0000\n",
            "2. Domain 2.0: Difficulty = 0.7762\n",
            "3. Domain 0.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 0.0\n",
            "Selected 3320 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.630302        \n",
            "1                0.546987        \n",
            "2                0.554320        \n",
            "3                0.530835        \n",
            "4                0.481427        \n",
            "5                0.450524        \n",
            "6                0.319364        \n",
            "7                0.443640        \n",
            "8                0.360870        \n",
            "9                0.294128        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.591953         0.904273         0.687681        \n",
            "1                1.628608         0.807913         0.820695        \n",
            "2                2.111973         1.227411         0.884562        \n",
            "3                2.433569         1.188679         1.244891        \n",
            "4                1.250818         0.847577         0.403241        \n",
            "5                1.111277         0.768660         0.342617        \n",
            "6                1.291466         0.804870         0.486596        \n",
            "7                2.965986         1.823151         1.142835        \n",
            "8                2.446538         1.184922         1.261616        \n",
            "9                1.434058         0.881833         0.552226        \n",
            "Counter({np.int64(2): 733, np.int64(1): 611, np.int64(5): 609, np.int64(3): 584, np.int64(0): 469, np.int64(4): 258})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "30               0.251528         0.779753         1.031281         0.974398         0.839114         0.766096         1.191481        \n",
            "31               0.108656         0.691664         0.800320         0.976506         0.853565         0.758417         1.158866        \n",
            "32               0.098291         0.756793         0.855084         0.986446         0.852601         0.773774         1.677596        \n",
            "33               0.128345         0.801765         0.930110         0.948795         0.811175         0.724158         1.416898        \n",
            "34               0.180129         0.804575         0.984704         0.970482         0.842004         0.749557         1.194199        \n",
            "35               0.152337         0.816576         0.968914         0.986446         0.858382         0.750148         1.197952        \n",
            "36               0.108885         0.937256         1.046141         0.972892         0.840077         0.755464         1.229043        \n",
            "37               0.111920         0.761268         0.873188         0.967470         0.815029         0.743060         1.181960        \n",
            "38               0.026447         0.748068         0.774515         0.991867         0.844894         0.764914         1.175016        \n",
            "39               0.082254         0.866822         0.949076         0.847892         0.718690         0.640284         1.216928        \n",
            "\n",
            "======== ROUND 4 ========\n",
            "Curriculum learning: Stage 4 (using 10 epochs)\n",
            "Curriculum learning: Stage 4\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0000\n",
            "2. Domain 0.0: Difficulty = 0.7389\n",
            "3. Domain 2.0: Difficulty = 0.9836\n",
            "Adding random harder domain: 2.0\n",
            "Selected 3320 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.815874        \n",
            "1                0.678295        \n",
            "2                0.462405        \n",
            "3                0.588271        \n",
            "4                0.472176        \n",
            "5                0.281467        \n",
            "6                0.325852        \n",
            "7                0.416877        \n",
            "8                0.416982        \n",
            "9                0.187268        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.580123         0.916169         0.663954        \n",
            "1                1.899799         1.118732         0.781067        \n",
            "2                1.825333         1.276377         0.548956        \n",
            "3                2.250695         1.197410         1.053285        \n",
            "4                1.293377         0.862910         0.430467        \n",
            "5                1.502678         0.992849         0.509829        \n",
            "6                1.712751         0.986753         0.725997        \n",
            "7                1.203454         0.866444         0.337009        \n",
            "8                1.519900         0.897287         0.622612        \n",
            "9                1.716344         1.252892         0.463452        \n",
            "Counter({np.int64(0): 733, np.int64(1): 596, np.int64(2): 596, np.int64(5): 499, np.int64(4): 423, np.int64(3): 417})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "40               0.173525         0.840891         1.014416         0.981325         0.857418         0.752510         1.190930        \n",
            "41               0.104567         0.807075         0.911643         0.984036         0.853565         0.750738         1.219105        \n",
            "42               0.276894         0.980149         1.257044         0.969578         0.842967         0.744241         1.199221        \n",
            "43               0.072614         0.977527         1.050142         0.990964         0.834297         0.763733         1.563133        \n",
            "44               0.047049         0.781355         0.828404         0.990964         0.844894         0.757236         1.647849        \n",
            "45               0.128408         0.856293         0.984701         0.988253         0.821773         0.756645         1.209893        \n",
            "46               0.087844         1.047065         1.134910         0.974096         0.818882         0.746604         1.214818        \n",
            "47               0.121268         0.875692         0.996961         0.993373         0.835260         0.756645         1.191050        \n",
            "48               0.084096         1.050608         1.134704         0.984337         0.823699         0.745422         1.186836        \n",
            "49               0.167791         1.041312         1.209104         0.989759         0.830443         0.756645         1.181110        \n",
            "\n",
            "======== ROUND 5 ========\n",
            "Curriculum learning: Stage 5 (using 10 epochs)\n",
            "Curriculum learning: Stage 5\n",
            "\n",
            "--- Domain Difficulty Ranking (easiest to hardest) ---\n",
            "1. Domain 1.0: Difficulty = 0.0433\n",
            "2. Domain 2.0: Difficulty = 0.5860\n",
            "3. Domain 0.0: Difficulty = 1.0000\n",
            "Adding random harder domain: 0.0\n",
            "Selected 3320 samples from 3 domains\n",
            "==== Feature update ====\n",
            "epoch            class_loss      \n",
            "0                0.901592        \n",
            "1                0.673274        \n",
            "2                0.602274        \n",
            "3                0.579021        \n",
            "4                0.543931        \n",
            "5                0.477194        \n",
            "6                0.341406        \n",
            "7                0.523742        \n",
            "8                0.260982        \n",
            "9                0.274696        \n",
            "==== Latent domain characterization ====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.649675         1.001846         0.647829        \n",
            "1                1.621003         1.007990         0.613014        \n",
            "2                1.328628         0.920128         0.408500        \n",
            "3                1.878263         1.300173         0.578090        \n",
            "4                1.494471         0.997250         0.497222        \n",
            "5                1.280684         0.867658         0.413026        \n",
            "6                1.174155         0.847330         0.326825        \n",
            "7                1.274258         0.831465         0.442793        \n",
            "8                1.253987         0.773287         0.480700        \n",
            "9                1.563664         1.109944         0.453720        \n",
            "Counter({np.int64(0): 723, np.int64(2): 675, np.int64(1): 631, np.int64(3): 446, np.int64(5): 441, np.int64(4): 348})\n",
            "==== Domain-invariant feature learning ====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "50               0.073421         1.029274         1.102695         0.984940         0.850674         0.750738         1.174530        \n",
            "51               0.116322         0.861576         0.977898         0.989157         0.850674         0.741288         1.179615        \n",
            "52               0.113358         0.787451         0.900809         0.988855         0.837187         0.761370         1.212685        \n",
            "53               0.053030         0.918727         0.971757         0.976205         0.824663         0.720614         1.248715        \n",
            "54               0.054883         0.905216         0.960099         0.985843         0.826590         0.743060         1.225359        \n",
            "55               0.096634         1.103024         1.199658         0.989458         0.843931         0.756054         1.808852        \n",
            "56               0.061110         0.860490         0.921600         0.996084         0.837187         0.753101         1.380357        \n",
            "57               0.129398         1.063117         1.192515         0.991265         0.821773         0.751329         1.205769        \n",
            "58               0.049434         0.850989         0.900423         0.993675         0.823699         0.753101         1.209413        \n",
            "59               0.116711         0.881589         0.998300         0.992771         0.826590         0.759008         1.181270        \n",
            "\n",
            "🎯 Final Target Accuracy: 0.7755\n",
            "\n",
            "📊 Running SHAP explainability...\n",
            "⚠️ Shape mismatch: SHAP values (10, 9600) vs features (10, 1600)\n",
            "⚠️ Using truncated shapes: SHAP (10, 1600), features (10, 1600)\n",
            "✅ Saved summary plot: ./train_output/shap_summary.png\n",
            "✅ Saved signal overlay: ./train_output/shap_overlay.png\n",
            "✅ Saved SHAP heatmap: ./train_output/shap_heatmap.png\n",
            "✅ Saved SHAP values to: ./train_output/shap_values.npy\n",
            "[SHAP] Accuracy Drop: 40.0000\n",
            "[SHAP] Flip Rate: 0.4000\n",
            "[SHAP] Confidence Δ: -0.0328\n",
            "[SHAP] AOPC: -0.0033\n",
            "[SHAP] Entropy: 8.5766\n",
            "[SHAP] Coherence: 0.0092\n",
            "[SHAP] Channel Variance: 0.0020\n",
            "[SHAP] Temporal Entropy: 7.0569\n",
            "[SHAP] Mutual Info: 0.0145\n",
            "[SHAP] PCA Alignment: 0.5681\n",
            "[SHAP] Jaccard (top-10): 0.0000\n",
            "[SHAP] Kendall's Tau: 0.1167\n",
            "[SHAP] Cosine Similarity: 0.3425\n",
            "✅ Saved interactive 4D SHAP plot: ./train_output/shap_4d_scatter.html\n",
            "✅ Saved interactive SHAP surface plot: ./train_output/shap_4d_surface.html\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning:\n",
            "\n",
            "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n",
            "✅ SHAP analysis completed successfully\n",
            "✅ Training metrics plot saved\n"
          ]
        }
      ]
    }
  ]
}
